{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo FruitScan - Comparaci√≥n de ResNet34, ResNet36 y VGG19\n",
    "\n",
    "Este notebook entrena y compara tres modelos de **Redes Neuronales Convolucionales (CNN)** utilizando un dataset comprimido en formato ZIP. El objetivo principal es evaluar el rendimiento de **ResNet18**, **ResNet34**, y **VGG19** en la clasificaci√≥n de frutas frescas y podridas.\n",
    "\n",
    "## Contenido:\n",
    "- **Dataset:** Im√°genes de frutas frescas y podridas (manzanas, bananas, naranjas).\n",
    "- **Modelos:** ResNet18, ResNet34 y VGG19 (pre-entrenados y fine-tuned).\n",
    "- **Evaluaci√≥n:** Curvas de p√©rdida, precisi√≥n por √©poca y matrices de confusi√≥n para cada modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## Paso 1: Descarga y Extracci√≥n del Dataset\n",
    "\n",
    "En este paso, se descarga el dataset de frutas directamente desde Google Drive y se extrae su contenido en el directorio `data/`. Esto asegura que las im√°genes est√©n disponibles para el entrenamiento y la validaci√≥n de los modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "\n",
    "import gdown\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Descargar directamente el ZIP desde Google Drive (sin necesidad de montar cuenta)\n",
    "file_id = \"1WEHp4vAUuu1wswR6tQSkxgC2shIpFIJS\"\n",
    "output = \"fruits_dataset.zip\"\n",
    "gdown.download(id=file_id, output=output, quiet=False)\n",
    "\n",
    "# Extraer contenido\n",
    "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data/\")\n",
    "\n",
    "# Confirmar clases\n",
    "extract_path = \"data/dataset/dataset/train\"\n",
    "print(\"‚úÖ Clases detectadas:\", os.listdir(extract_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 2: Importaci√≥n de Librer√≠as\n",
    "\n",
    "Se importan todas las librer√≠as necesarias para la manipulaci√≥n de datos, la construcci√≥n y entrenamiento de modelos de PyTorch, y la visualizaci√≥n de resultados. Esto incluye `torch`, `torchvision`, `matplotlib`, y `sklearn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 3: Configuraciones Iniciales y Preparaci√≥n del Dataset\n",
    "\n",
    "Aqu√≠ se definen los par√°metros generales como el tama√±o del batch, las dimensiones de las im√°genes y el n√∫mero de √©pocas. Adem√°s, se configuran las **transformaciones de datos** necesarias (redimensionamiento, conversi√≥n a tensor y normalizaci√≥n) y se cargan los datasets de entrenamiento y prueba utilizando `ImageFolder` de `torchvision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metros generales\n",
    "batch_size = 8\n",
    "img_size = 224\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_dir = \"data/dataset/dataset\"\n",
    "\n",
    "# Transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset usando carpetas train/ y test/ directamente\n",
    "train_dir = \"data/dataset/dataset/train\"\n",
    "test_dir = \"data/dataset/dataset/test\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset  = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(\"Clases detectadas:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 4: Funci√≥n de Entrenamiento Gen√©rica\n",
    "\n",
    "Se define una funci√≥n `entrenar_modelo` que encapsula el bucle de entrenamiento y validaci√≥n. Esta funci√≥n es gen√©rica y puede ser utilizada con cualquiera de los modelos de CNN. Calcula y retorna las p√©rdidas de entrenamiento y validaci√≥n, las precisiones de validaci√≥n, y las predicciones reales para la generaci√≥n de la matriz de confusi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo(model, train_loader, val_loader, optimizer, criterion, epochs, nombre):\n",
    "    model = model.to(device)\n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validaci√≥n\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"\\u2705 Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "    return model, train_losses, val_losses, val_accuracies, y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 5: Entrenamiento de Modelos\n",
    "\n",
    "Aqu√≠ se instancian, modifican (para adaptar la capa de salida al n√∫mero de clases) y entrenan los tres modelos pre-entrenados: **ResNet18**, **ResNet34**, y **VGG19**. Para cada modelo, se congela la mayor√≠a de las capas pre-entrenadas y solo se entrena la capa de clasificaci√≥n final. Se utiliza el optimizador Adam y la funci√≥n de p√©rdida CrossEntropyLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet18\n",
    "print(\"\\n--- Entrenando ResNet18 ---\")\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, len(class_names))\n",
    "\n",
    "optimizer_r18 = optim.Adam(resnet18.fc.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18, r18_train, r18_val, r18_acc, y_true_r18, y_pred_r18 = entrenar_modelo(\n",
    "    resnet18, train_loader, val_loader, optimizer_r18, criterion, epochs, \"ResNet18\"\n",
    ")\n",
    "\n",
    "# ResNet34\n",
    "print(\"\\n--- Entrenando ResNet34 ---\")\n",
    "resnet34 = models.resnet34(pretrained=True)\n",
    "for param in resnet34.parameters():\n",
    "    param.requires_grad = False\n",
    "resnet34.fc = nn.Linear(resnet34.fc.in_features, len(class_names))\n",
    "\n",
    "optimizer_r34 = optim.Adam(resnet34.fc.parameters(), lr=0.001)\n",
    "\n",
    "resnet34, r34_train, r34_val, r34_acc, y_true_r34, y_pred_r34 = entrenar_modelo(\n",
    "    resnet34, train_loader, val_loader, optimizer_r34, criterion, epochs, \"ResNet34\"\n",
    ")\n",
    "\n",
    "# VGG19\n",
    "print(\"\\n--- Entrenando VGG19 ---\")\n",
    "vgg19 = models.vgg19(pretrained=True)\n",
    "for param in vgg19.features.parameters():\n",
    "    param.requires_grad = False\n",
    "vgg19.classifier[6] = nn.Linear(vgg19.classifier[6].in_features, len(class_names))\n",
    "\n",
    "optimizer_vgg = optim.Adam(vgg19.classifier.parameters(), lr=0.001)\n",
    "\n",
    "vgg19, vgg_train, vgg_val, vgg_acc, y_true_vgg, y_pred_vgg = entrenar_modelo(\n",
    "    vgg19, train_loader, val_loader, optimizer_vgg, criterion, epochs, \"VGG19\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 6: Comparaci√≥n de M√©tricas de los Modelos\n",
    "\n",
    "Se generan gr√°ficos para comparar visualmente las curvas de p√©rdida de validaci√≥n y la precisi√≥n de validaci√≥n a lo largo de las √©pocas para cada uno de los modelos. Adem√°s, se imprime la precisi√≥n final (macro average) de cada modelo para una comparaci√≥n directa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_comparison(metric_dict, title, ylabel):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for label, values in metric_dict.items():\n",
    "        plt.plot(values, label=label)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Diccionarios con los valores por modelo\n",
    "loss_val_dict = {\n",
    "    \"ResNet18\": r18_val,\n",
    "    \"ResNet34\": r34_val,\n",
    "    \"VGG19\": vgg_val\n",
    "}\n",
    "\n",
    "acc_val_dict = {\n",
    "    \"ResNet18\": r18_acc,\n",
    "    \"ResNet34\": r34_acc,\n",
    "    \"VGG19\": vgg_acc\n",
    "}\n",
    "\n",
    "# C√°lculo de precisi√≥n por √©poca no disponible directamente -> omitimos para no inventar valores\n",
    "# Se podr√≠a hacer con batches pero complica la funci√≥n, por ahora mostramos precisi√≥n final por modelo\n",
    "def calcular_precision_final(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "precision_dict = {\n",
    "    \"ResNet18\": calcular_precision_final(y_true_r18, y_pred_r18),\n",
    "    \"ResNet34\": calcular_precision_final(y_true_r34, y_pred_r34),\n",
    "    \"VGG19\": calcular_precision_final(y_true_vgg, y_pred_vgg),\n",
    "}\n",
    "\n",
    "plot_metric_comparison(loss_val_dict, \"Validation Loss\", \"Loss\")\n",
    "plot_metric_comparison(acc_val_dict, \"Validation Accuracy\", \"Accuracy\")\n",
    "\n",
    "# Mostrar precisi√≥n final\n",
    "print(\"üìå Precision por modelo (macro avg):\")\n",
    "for modelo, prec in precision_dict.items():\n",
    "    print(f\"{modelo}: {prec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 6.1: An√°lisis Profundo y Determinaci√≥n del Mejor Modelo\n",
    "\n",
    "La fase de an√°lisis es donde interpretamos los resultados num√©ricos y visuales para extraer conclusiones significativas sobre el rendimiento de cada modelo. Bas√°ndonos en los gr√°ficos de curvas de p√©rdida de validaci√≥n, la precisi√≥n de validaci√≥n a lo largo de las √©pocas, y la precisi√≥n final (`macro avg`), podemos identificar el modelo que exhibe el rendimiento m√°s robusto y generalizado para nuestro problema de clasificaci√≥n de frutas frescas vs. podridas.\n",
    "\n",
    "Para realizar esta determinaci√≥n, nos enfocamos en las siguientes m√©tricas clave:\n",
    "\n",
    "1.  **P√©rdida de Validaci√≥n (`Validation Loss`)**: Este valor es un indicador crucial de cu√°n bien est√° aprendiendo el modelo y generalizando a datos no vistos. Un `Validation Loss` bajo y estable a lo largo de las √©pocas sugiere que el modelo no solo est√° aprendiendo de manera efectiva, sino que tambi√©n evita el sobreajuste (`overfitting`). Una p√©rdida que disminuye continuamente en el entrenamiento pero aumenta en la validaci√≥n es una se√±al clara de sobreajuste.\n",
    "\n",
    "2.  **Precisi√≥n de Validaci√≥n (`Validation Accuracy`)**: Esta m√©trica nos dice la proporci√≥n de predicciones correctas que el modelo realiza en el conjunto de validaci√≥n. Un valor m√°s alto indica una mejor capacidad de clasificaci√≥n. Es importante observar no solo el valor final, sino tambi√©n la trayectoria: ¬øla precisi√≥n se estabiliza, sigue mejorando o comienza a disminuir (posible sobreajuste)?\n",
    "\n",
    "3.  **Precisi√≥n Final (`Precision (macro avg)`)**: Como se explic√≥ anteriormente, la precisi√≥n macro promedio es fundamental porque calcula la precisi√≥n para cada clase de forma independiente y luego promedia esos valores. Esto es especialmente valioso en datasets donde las clases pueden no estar balanceadas, ya que asegura que el rendimiento en clases minoritarias no sea ignorado por un buen rendimiento en clases mayoritarias. Una alta precisi√≥n macro promedio indica que el modelo es consistentemente bueno en todas las categor√≠as de frutas.\n",
    "\n",
    "### **Observaciones T√≠picas y Fundamentos Arquitect√≥nicos:**\n",
    "\n",
    "* **VGG19**: Esta arquitectura es conocida por su simplicidad (bloques de capas convolucionales y de *pooling* seguidos por capas densas) y su gran profundidad. Sin embargo, su enorme n√∫mero de par√°metros puede hacer que sea m√°s lenta de entrenar y, en tareas de *transfer learning* donde solo se entrena la capa final, a veces puede no alcanzar la misma eficiencia o capacidad de adaptaci√≥n que las arquitecturas con **conexiones residuales**. Su rendimiento puede ser bueno, pero a menudo se ve superado por las ResNets en datasets m√°s complejos o con menos datos disponibles para el *fine-tuning* de la capa final.\n",
    "\n",
    "* **ResNet18**: Como una de las arquitecturas ResNet m√°s ligeras, ResNet18 introduce las innovadoras **conexiones residuales (skip connections)**. Estas conexiones permiten que la informaci√≥n pase directamente de capas anteriores a capas posteriores, mitigando el problema del *vanishing gradient* (desaparici√≥n del gradiente) en redes muy profundas. Esto facilita el entrenamiento y permite a la red aprender caracter√≠sticas m√°s complejas. ResNet18 generalmente ofrece un excelente equilibrio entre un rendimiento competitivo y una eficiencia computacional razonable, lo que la convierte en una opci√≥n muy popular para *transfer learning*.\n",
    "\n",
    "* **ResNet34**: Con m√°s capas que ResNet18 (pero a√∫n dentro de la misma familia de arquitecturas residuales), ResNet34 tiene una mayor capacidad de modelado. Esto le permite capturar patrones y caracter√≠sticas m√°s intrincadas en las im√°genes. En muchos casos, ResNet34 puede lograr una **precisi√≥n ligeramente superior** a ResNet18 y una **menor p√©rdida de validaci√≥n**, aunque a costa de un tiempo de entrenamiento un poco mayor y un consumo de recursos computacionales marginalmente m√°s alto. Su dise√±o intr√≠nseco con bloques residuales le permite escalar bien la profundidad sin los problemas de optimizaci√≥n que enfrentan otras redes profundas como VGG sin estas conexiones.\n",
    "\n",
    "**Conclusi√≥n y Raz√≥n del Mejor Rendimiento (basada en resultados esperados y experiencia general):**\n",
    "\n",
    "Tras una revisi√≥n de los gr√°ficos de *Validation Loss* y *Validation Accuracy*, as√≠ como la m√©trica num√©rica de *Precision (macro avg)*, se espera que el modelo **ResNet34** demuestre ser el de **mejor rendimiento** para esta tarea de clasificaci√≥n de frutas.\n",
    "\n",
    "Las razones principales de su superioridad probable son:\n",
    "1.  **Profundidad Optimizada**: ResNet34 es lo suficientemente profunda como para aprender representaciones ricas y complejas de las im√°genes, pero no tan profunda como para volverse intratable con el *transfer learning* en este dataset. Su arquitectura, con m√°s bloques residuales que ResNet18, le confiere una mayor capacidad de aprendizaje.\n",
    "2.  **Eficacia de las Conexiones Residuales**: Las *skip connections* de la familia ResNet son clave. Permiten que los gradientes fluyan m√°s f√°cilmente a trav√©s de la red, lo que evita la saturaci√≥n de gradientes y facilita el entrenamiento de capas m√°s profundas. Esto es crucial para aprender las sutiles diferencias entre frutas frescas y podridas, incluso con cambios en texturas, colores o formas.\n",
    "3.  **Generalizaci√≥n Mejorada**: Las ResNets, gracias a su dise√±o, tienden a generalizar mejor a datos no vistos, lo que se refleja en una menor p√©rdida de validaci√≥n y una mayor precisi√≥n de validaci√≥n en comparaci√≥n con VGG19, que podr√≠a ser m√°s propensa al sobreajuste o a una convergencia m√°s lenta en este tipo de escenarios de *transfer learning*.\n",
    "\n",
    "En resumen, el **ResNet34** logra un equilibrio √≥ptimo entre complejidad de modelo y la capacidad de aprender caracter√≠sticas discriminativas para esta tarea, superando t√≠picamente a sus contrapartes en t√©rminos de precisi√≥n y robustez. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 7: Matrices de Confusi√≥n\n",
    "\n",
    "Se generan y muestran las matrices de confusi√≥n normalizadas para cada modelo. Estas matrices permiten visualizar el rendimiento de clasificaci√≥n por clase, identificando d√≥nde los modelos aciertan y d√≥nde se equivocan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_confusion(y_true, y_pred, modelo):\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp.plot(cmap='Blues', ax=ax, xticks_rotation=45)\n",
    "    plt.title(f\"Normalized Confusion Matrix - {modelo}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_confusion(y_true_r18, y_pred_r18, \"ResNet18\")\n",
    "mostrar_confusion(y_true_r34, y_pred_r34, \"ResNet34\")\n",
    "mostrar_confusion(y_true_vgg, y_pred_vgg, \"VGG19\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 8: Guardado de Modelos\n",
    "\n",
    "Los pesos entrenados de cada modelo se guardan en archivos `.pth` separados. Esto permite recargar y reutilizar los modelos en el futuro sin necesidad de reentrenarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet18.state_dict(), \"model_resnet18.pth\")\n",
    "torch.save(resnet34.state_dict(), \"model_resnet34.pth\")\n",
    "torch.save(vgg19.state_dict(), \"model_vgg19.pth\")\n",
    "\n",
    "print(\"‚úÖ Modelos guardados correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 9: Mostrar Informaci√≥n sobre la Clase Predicha (Simulaci√≥n)\n",
    "\n",
    "Este paso simula c√≥mo se podr√≠a usar la predicci√≥n de un modelo en una aplicaci√≥n real, como una interfaz de usuario. Se proporciona informaci√≥n descriptiva para cada clase de fruta, demostrando c√≥mo se podr√≠a integrar la salida del modelo con datos adicionales para el usuario final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info = {\n",
    "    'freshapples': 'These are fresh apples. A good source of fiber and vitamin C.',\n",
    "    'freshbanana': 'These are fresh bananas. High in potassium.',\n",
    "    'freshoranges': 'These are fresh oranges. Rich in vitamin C and antioxidants.',\n",
    "    'rottenapples': 'These are rotten apples. Not suitable for consumption.',\n",
    "    'rottenbanana': 'These are rotten bananas. Sometimes usable for cooking, but handle with care.',\n",
    "    'rottenoranges': 'These are rotten oranges. Should be discarded.'\n",
    "}\n",
    "\n",
    "# Simulaci√≥n de uso posterior (por ejemplo, en Streamlit)\n",
    "# Podr√≠as reemplazar 'predicted_class_name' por la clase detectada en tiempo real\n",
    "predicted_class_name = \"freshapples\"\n",
    "\n",
    "if predicted_class_name in fruit_info:\n",
    "    print(f\"\\n‚ÑπÔ∏è Info for predicted fruit ({predicted_class_name}):\")\n",
    "    print(fruit_info[predicted_class_name])\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è No info available for the predicted class.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
