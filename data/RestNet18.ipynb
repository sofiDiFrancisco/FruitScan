{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {}, 
"source": [
    "# Clasificaci√≥n de Frutas: Entrenamiento con ResNet18\n",
    "\n",
    "Este notebook documenta paso a paso el proceso completo para desarrollar un clasificador de im√°genes de frutas frescas y podridas utilizando aprendizaje por transferencia con ResNet18.\n",
    "\n",
    "## Objetivo\n",
    "Crear un modelo de clasificaci√≥n de im√°genes capaz de distinguir entre frutas frescas y podridas, con potencial aplicaci√≥n en sistemas de control de calidad automatizados para la industria alimentaria.\n",
    "\n",
    "## Dataset\n",
    "Utilizaremos el dataset \"Fruits Fresh and Rotten for Classification\" disponible en Kaggle, que contiene im√°genes de 6 tipos de frutas (manzanas, pl√°tanos, naranjas, etc.) en dos estados: fresco y podrido.\n",
    "\n",
    "## Metodolog√≠a\n",
    "1. Transfer Learning con ResNet18 pre-entrenado en ImageNet\n",
    "2. Fine-tuning solo en la capa fully-connected final\n",
    "3. Entrenamiento durante 10 √©pocas con validaci√≥n\n",
    "4. Evaluaci√≥n del rendimiento\n",
    "\n",
    "## Requisitos\n",
    "- Python 3.7+\n",
    "- PyTorch 1.8+\n",
    "- Torchvision\n",
    "- KaggleHub (para descargar el dataset)\n",
    "- Matplotlib (para visualizaci√≥n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19056a3",
   "metadata": {},
   "source": [
    "## Paso 1: Importaci√≥n de Librer√≠as\n",
    "\n",
    "Importamos todas las librer√≠as necesarias para el proyecto:\n",
    "- KaggleHub: Para descargar el dataset\n",
    "- PyTorch: Framework principal para deep learning\n",
    "- Torchvision: Para modelos pre-entrenados y transformaciones de im√°genes\n",
    "- Matplotlib: Para visualizaci√≥n de resultados\n",
    "- OS: Para manejo de rutas de archivos"
   ]
  },
  {
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae9198",
   "metadata": {},
   "source": [
    "## Paso 2: Descarga del Dataset desde Kaggle Hub\n",
    "\n",
    "Descargamos el dataset directamente desde Kaggle Hub utilizando la API de kagglehub.\n",
    "\n",
    "**Nota:** Requiere autenticaci√≥n previa en Kaggle y configuraci√≥n de API token."
   ]
  },
  {
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el token de Kaggle si es necesario\n",
    "# os.environ['KAGGLE_USERNAME'] = 'tu_usuario'\n",
    "# os.environ['KAGGLE_KEY'] = 'tu_key'\n",
    "\n",
    "try:\n",
    "    path = kagglehub.dataset_download(\"sriramr/fruits-fresh-and-rotten-for-classification\")\n",
    "    print(\"‚úÖ Dataset descargado correctamente\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al descargar el dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59be97c",
   "metadata": {},
   "source": [
    "## Paso 3: Configuraci√≥n Inicial y Transformaciones\n",
    "\n",
    "Configuramos los par√°metros b√°sicos del modelo y definimos las transformaciones para el preprocesamiento de im√°genes:\n",
    "\n",
    "- **Tama√±o del batch**: 128 (ajustable seg√∫n memoria GPU)\n",
    "- **Tama√±o de imagen**: 224x224 (requerido por ResNet)\n",
    "- **Transformaciones**:\n",
    "  - Redimensionamiento\n",
    "  - Conversi√≥n a tensor\n",
    "  - Normalizaci√≥n (usando medias y std de ImageNet)\n",
    "\n",
    "**Nota:** La normalizaci√≥n usa valores est√°ndar de ImageNet ya que ResNet fue pre-entrenado con estos valores."
   ]
  },
  {
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n b√°sica\n",
    "batch_size = 128 # Lote reducido para prevenir desbordamientos\n",
    "img_size = 224  # Tama√±o requerido por ResNet\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Dispositivo de ejecuci√≥n: {device}\")\n",
    "\n",
    "# Transformaciones para preprocesamiento de im√°genes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),  # Redimensionar a 224x224\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalizar con valores de ImageNet\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n y transformaciones definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b42f3",
   "metadata": {},
   "source": [
    "## Paso 4: Carga y Divisi√≥n del Dataset\n",
    "\n",
    "Cargamos el dataset completo y lo dividimos en conjuntos de entrenamiento (80%) y validaci√≥n (20%).\n",
    "\n",
    "**Detalles importantes:**\n",
    "- Usamos ImageFolder que autom√°ticamente organiza las im√°genes por clases seg√∫n la estructura de directorios\n",
    "- La semilla aleatoria (seed=42) asegura reproducibilidad\n",
    "- Los DataLoaders manejan el cargado eficiente de datos durante el entrenamiento"
   ]
  },
  {
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Cargar dataset completo\n",
    "    full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    class_names = full_dataset.classes\n",
    "    print(f\"üîç Clases detectadas: {class_names}\")\n",
    "    print(f\"üìä Total de im√°genes: {len(full_dataset)}\")\n",
    "\n",
    "    # Dividir en entrenamiento y validaci√≥n\n",
    "    val_split = 0.2  # 20% para validaci√≥n\n",
    "    val_size = int(len(full_dataset) * val_split)\n",
    "    train_size = len(full_dataset) - val_size\n",
    "    \n",
    "    # Fijar semilla para reproducibilidad\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "    print(f\"üöÇ Im√°genes de entrenamiento: {len(train_dataset)}\")\n",
    "    print(f\"üß™ Im√°genes de validaci√≥n: {len(val_dataset)}\")\n",
    "\n",
    "    # Crear DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    print(\"‚úÖ Dataset cargado y dividido correctamente\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al cargar el dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee582dd",
   "metadata": {},
   "source": [
    "## Paso 5: Definici√≥n del Modelo\n",
    "\n",
    "Cargamos ResNet18 pre-entrenado en ImageNet y adaptamos para nuestro problema:\n",
    "\n",
    "1. Cargamos el modelo pre-entrenado\n",
    "2. Congelamos todos los par√°metros (transfer learning)\n",
    "3. Reemplazamos la √∫ltima capa fully-connected para que tenga la salida adecuada para nuestras clases\n",
    "4. Movemos el modelo al dispositivo (GPU/CPU)\n",
    "\n",
    "**Estrategia de Transfer Learning:**\n",
    "- Congelamos todas las capas excepto la √∫ltima\n",
    "- Esto permite reutilizar las caracter√≠sticas aprendidas en ImageNet\n",
    "- Solo entrenamos la nueva capa fully-connected para nuestra tarea espec√≠fica"
   ]
  },
  {
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Cargar ResNet18 pre-entrenado\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    print(\"üéØ ResNet18 cargado (pre-entrenado en ImageNet)\")\n",
    "\n",
    "    # Congelar todos los par√°metros\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    print(\"‚ùÑÔ∏è Par√°metros congelados (excepto √∫ltima capa)\")\n",
    "\n",
    "    # Reemplazar la capa fully-connected\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, len(class_names))\n",
    "    print(f\"üîÑ Capa FC reemplazada para {len(class_names)} clases\")\n",
    "\n",
    "    # Mover modelo al dispositivo\n",
    "    model = model.to(device)\n",
    "    print(f\"üìå Modelo movido a {device}\")\n",
    "    \n",
    "    print(\"‚úÖ Modelo definido correctamente\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al configurar el modelo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e104665",
   "metadata": {},
   "source": [
    "## Paso 6: Configuraci√≥n del Entrenamiento\n",
    "\n",
    "Definimos los par√°metros para el entrenamiento:\n",
    "\n",
    "- **Funci√≥n de p√©rdida**: CrossEntropyLoss (adecuada para clasificaci√≥n)\n",
    "- **Optimizador**: Adam con learning rate de 0.001\n",
    "- **√âpocas**: 10 (suficiente para fine-tuning)\n",
    "\n",
    "**Notas:**\n",
    "- Adam es una buena opci√≥n por su adaptabilidad\n",
    "- El LR es bajo porque solo estamos ajustando la √∫ltima capa\n",
    "- Podr√≠a implementarse learning rate scheduler para mejor ajuste"
   ]
  },
  {
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n de p√©rdida (clasificaci√≥n multi-clase)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizador (solo para los par√°metros de la √∫ltima capa)\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# N√∫mero de √©pocas\n",
    "epochs = 10\n",
    "\n",
    "print(\"‚öôÔ∏è Configuraci√≥n de entrenamiento:\")\n",
    "print(f\"- Funci√≥n de p√©rdida: {criterion.__class__.__name__}\")\n",
    "print(f\"- Optimizador: {optimizer.__class__.__name__} (lr=0.001)\")\n",
    "print(f\"- √âpocas: {epochs}\")\n",
    "print(\"‚úÖ Configuraci√≥n de entrenamiento completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa7a15",
   "metadata": {},
   "source": [
    "## Paso 7: Entrenamiento del Modelo\n",
    "\n",
    "Ciclo completo de entrenamiento y validaci√≥n:\n",
    "\n",
    "1. **Modo entrenamiento**:\n",
    "   - Forward pass\n",
    "   - C√°lculo de p√©rdida\n",
    "   - Backpropagation\n",
    "   - Actualizaci√≥n de pesos\n",
    "\n",
    "2. **Modo evaluaci√≥n**:\n",
    "   - Validaci√≥n sin gradientes\n",
    "   - C√°lculo de p√©rdida y precisi√≥n\n",
    "   - Monitoreo del rendimiento\n",
    "\n",
    "**M√©tricas guardadas:**\n",
    "- P√©rdida de entrenamiento por √©poca\n",
    "- P√©rdida de validaci√≥n por √©poca\n",
    "- Precisi√≥n en validaci√≥n"
   ]
  },
  {
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para guardar m√©tricas\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(\"üöÄ Comenzando entrenamiento...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # --- Fase de Entrenamiento ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Mover datos al dispositivo\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass y optimizaci√≥n\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calcular p√©rdida promedio por √©poca\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    # --- Fase de Validaci√≥n ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Calcular precisi√≥n\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calcular m√©tricas de validaci√≥n\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    val_accuracies.append(accuracy)\n",
    "    \n",
    "    # Mostrar progreso\n",
    "    print(f\"‚úÖ Epoch {epoch+1}/{epochs} - \"\n",
    "          f\"Train Loss: {epoch_loss:.4f} - \"\n",
    "          f\"Val Loss: {val_loss:.4f} - \"\n",
    "          f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"üéâ Entrenamiento completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa756bbd",
   "metadata": {},
   "source": [
    "## Paso 8: Visualizaci√≥n de Resultados\n",
    "\n",
    "Graficamos las curvas de p√©rdida y precisi√≥n para analizar el rendimiento del modelo:\n",
    "\n",
    "1. **Curva de p√©rdida**: Muestra la evoluci√≥n de la p√©rdida en entrenamiento y validaci√≥n\n",
    "2. **Curva de precisi√≥n**: Muestra la precisi√≥n en el conjunto de validaci√≥n por √©poca\n",
    "\n",
    "**An√°lisis esperado:**\n",
    "- La p√©rdida deber√≠a disminuir en ambas curvas\n",
    "- La precisi√≥n deber√≠a aumentar\n",
    "- Si hay overfitting, la p√©rdida de validaci√≥n comenzar√≠a a aumentar"
   ]
  },
  {
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gr√°fico de p√©rdidas\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Entrenamiento')\n",
    "plt.plot(val_losses, label='Validaci√≥n')\n",
    "plt.xlabel('√âpocas')\n",
    "plt.ylabel('P√©rdida')\n",
    "plt.title('Curva de P√©rdida')\n",
    "plt.legend()\n",
    "\n",
    "# Gr√°fico de precisi√≥n\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies, label='Validaci√≥n', color='green')\n",
    "plt.xlabel('√âpocas')\n",
    "plt.ylabel('Precisi√≥n (%)')\n",
    "plt.title('Precisi√≥n en Validaci√≥n')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
   "id": "d5fcec54",
   "metadata": {},
   "source": [
    "## Paso 9: Guardado del Modelo\n",
    "\n",
    "Guardamos el modelo entrenado para su uso futuro:\n",
    "\n",
    "- Solo guardamos los par√°metros del modelo (state_dict)\n",
    "- Esto permite cargar el modelo en cualquier momento\n",
    "- El archivo tiene extensi√≥n .pth (convenci√≥n PyTorch)\n",
    "\n",
    "**Nota:** Para cargar el modelo despu√©s, necesitaremos reconstruir la misma arquitectura y luego cargar los par√°metros."
   ]
  },
  {
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_path = \"fruitscan_model.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"\\nüíæ Modelo guardado como: {model_path}\")\n",
    "    print(f\"Tama√±o del archivo: {os.path.getsize(model_path)/1024:.2f} KB\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al guardar el modelo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5e3f1",
   "metadata": {},
   "source": [
    "## Paso 10: Conclusiones y Pasos Siguientes\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "- Modelo entrenado con transfer learning usando ResNet18\n",
    "- Precisi√≥n final en validaci√≥n: 98%\n",
    "- Tiempo de entrenamiento: 18 minutos\n",
    "\n",
    "**Usos potenciales:**\n",
    "- Sistemas de clasificaci√≥n autom√°tica en l√≠neas de producci√≥n\n",
    "- Aplicaciones m√≥viles para consumidores\n",
    "- Integraci√≥n con sistemas de control de inventario\n",
    "\n",
    "**C√≥mo usar el modelo guardado:**\n",
    "```python\n",
    "# Cargar la arquitectura del modelo\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# Cargar los par√°metros entrenados\n",
    "model.load_state_dict(torch.load('fruitscan_model.pth'))\n",
    "model.eval()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
