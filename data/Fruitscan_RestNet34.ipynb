{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n de Frutas con ResNet34\n",
    "\n",
    "Este notebook implementa un clasificador de im√°genes para distinguir entre frutas frescas y podridas utilizando transfer learning con ResNet34.\n",
    "\n",
    "## Objetivos\n",
    "- Desarrollar un modelo de clasificaci√≥n de im√°genes preciso\n",
    "- Implementar transfer learning con ResNet34\n",
    "- Evaluar el rendimiento del modelo\n",
    "- Probar el modelo con inferencia en im√°genes reales\n",
    "\n",
    "## Dataset\n",
    "Utilizaremos el dataset \"Fruits Fresh and Rotten for Classification\" de Kaggle que contiene:\n",
    "- Im√°genes de frutas en estados fresco y podrido\n",
    "- Organizado en carpetas por clase\n",
    "- Divisi√≥n autom√°tica en train/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de Librer√≠as\n",
    "\n",
    "Importamos todas las dependencias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from google.colab import drive\n",
    "from PIL import Image\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descarga y Configuraci√≥n del Dataset\n",
    "\n",
    "Descargamos el dataset y configuramos los par√°metros b√°sicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    path = kagglehub.dataset_download(\"sriramr/fruits-fresh-and-rotten-for-classification\")\n",
    "    print(\"‚úÖ Dataset descargado correctamente\")\n",
    "    print(\"Ubicaci√≥n del dataset:\", path)\n",
    "    \n",
    "    # Configuraci√≥n b√°sica\n",
    "    batch_size = 128  # Tama√±o reducido para evitar problemas de memoria\n",
    "    img_size = 224   # Tama√±o requerido por ResNet\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"üöÄ Dispositivo de ejecuci√≥n: {device}\")\n",
    "    \n",
    "    # Transformaciones para las im√°genes\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    print(\"‚úÖ Configuraci√≥n inicial completada\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error en la descarga: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carga de Datos\n",
    "\n",
    "Cargamos los datasets de entrenamiento y validaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Rutas a los directorios\n",
    "    train_data_dir = os.path.join(path, 'dataset', 'train')\n",
    "    val_data_dir = os.path.join(path, 'dataset', 'test')\n",
    "    \n",
    "    # Cargar datasets\n",
    "    train_dataset = datasets.ImageFolder(root=train_data_dir, transform=transform)\n",
    "    val_dataset = datasets.ImageFolder(root=val_data_dir, transform=transform)\n",
    "    \n",
    "    # Obtener nombres de clases\n",
    "    class_names = train_dataset.classes\n",
    "    print(f\"üîç Clases detectadas: {class_names}\")\n",
    "    print(f\"üìä Im√°genes de entrenamiento: {len(train_dataset)}\")\n",
    "    print(f\"üìä Im√°genes de validaci√≥n: {len(val_dataset)}\")\n",
    "    \n",
    "    # Crear DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    print(\"‚úÖ Datasets cargados correctamente\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al cargar datos: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuraci√≥n del Modelo\n",
    "\n",
    "Preparamos ResNet34 con transfer learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Cargar modelo pre-entrenado\n",
    "    model = models.resnet34(pretrained=True)\n",
    "    print(\"üéØ ResNet34 cargado (pre-entrenado en ImageNet)\")\n",
    "    \n",
    "    # Congelar par√°metros\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    print(\"‚ùÑÔ∏è Par√°metros congelados (excepto √∫ltima capa)\")\n",
    "    \n",
    "    # Reemplazar capa final\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, len(class_names))\n",
    "    print(f\"üîÑ Capa FC reemplazada para {len(class_names)} clases\")\n",
    "    \n",
    "    # Mover modelo al dispositivo\n",
    "    model = model.to(device)\n",
    "    print(f\"üìå Modelo movido a {device}\")\n",
    "    \n",
    "    print(\"‚úÖ Modelo configurado correctamente\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al configurar modelo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configuraci√≥n del Entrenamiento\n",
    "\n",
    "Definimos hiperpar√°metros y funciones de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de entrenamiento\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "# Variables para m√©tricas\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(\"‚öôÔ∏è Configuraci√≥n de entrenamiento:\")\n",
    "print(f\"- Funci√≥n de p√©rdida: {criterion.__class__.__name__}\")\n",
    "print(f\"- Optimizador: {optimizer.__class__.__name__} (lr=0.001)\")\n",
    "print(f\"- √âpocas: {epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entrenamiento del Modelo\n",
    "\n",
    "Ejecutamos el ciclo de entrenamiento y validaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Comenzando entrenamiento...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Fase de entrenamiento\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Fase de validaci√≥n\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    val_accuracies.append(accuracy)\n",
    "    \n",
    "    print(f\"‚úÖ Epoch {epoch+1}/{epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"üéâ Entrenamiento completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizaci√≥n de Resultados\n",
    "\n",
    "Graficamos las curvas de aprendizaje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gr√°fico de p√©rdidas\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Entrenamiento')\n",
    "plt.plot(val_losses, label='Validaci√≥n')\n",
    "plt.xlabel('√âpocas')\n",
    "plt.ylabel('P√©rdida')\n",
    "plt.title('Curva de P√©rdida')\n",
    "plt.legend()\n",
    "\n",
    "# Gr√°fico de precisi√≥n\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies, color='green')\n",
    "plt.xlabel('√âpocas')\n",
    "plt.ylabel('Precisi√≥n (%)')\n",
    "plt.title('Precisi√≥n en Validaci√≥n')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Guardado del Modelo\n",
    "\n",
    "Almacenamos el modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_path = \"modelo_resnet34.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"üíæ Modelo guardado como: {model_path}\")\n",
    "    print(f\"Tama√±o: {os.path.getsize(model_path)/1024:.2f} KB\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al guardar modelo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inferencia con el Modelo\n",
    "\n",
    "Probamos el modelo con una imagen de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Fase de Inferencia ---\")\n",
    "\n",
    "# Obtener una imagen de ejemplo\n",
    "sample_image_path, _ = val_dataset.samples[0]\n",
    "print(f\"‚è≥ Procesando imagen: {sample_image_path}\")\n",
    "\n",
    "# Cargar y preprocesar la imagen\n",
    "image = Image.open(sample_image_path).convert('RGB')\n",
    "image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "# Realizar inferencia\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(image)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Mostrar resultado\n",
    "predicted_class = class_names[predicted.item()]\n",
    "print(f\"‚úÖ Predicci√≥n: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusiones\n",
    "\n",
    "**Resultados obtenidos:**\n",
    "- Modelo ResNet34 adaptado para clasificaci√≥n de frutas\n",
    "- Alta precisi√≥n en validaci√≥n (~98%)\n",
    "- Implementaci√≥n lista para producci√≥n\n",
    "\n",
    "**Uso del modelo guardado:**\n",
    "```python\n",
    "model = models.resnet34(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load('modelo_resnet34.pth'))\n",
    "model.eval()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
