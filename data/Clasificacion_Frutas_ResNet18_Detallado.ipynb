{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b84ca6",
   "metadata": {},
   "source": [
    "# 🧠 Clasificación de Frutas Frescas y Podridas con ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d9f03",
   "metadata": {},
   "source": [
    "\n",
    "Este notebook implementa una solución de visión por computadora para la **clasificación de frutas frescas y podridas**, utilizando una arquitectura **ResNet18 preentrenada** sobre ImageNet. Se siguen los siguientes pasos:\n",
    "\n",
    "1. **Importación de librerías** necesarias para procesamiento de datos, visualización, entrenamiento e inferencia.\n",
    "2. **Descarga del dataset** directamente desde Kaggle utilizando `kagglehub`.\n",
    "3. **Preprocesamiento de imágenes**, incluyendo redimensionamiento y normalización.\n",
    "4. **Configuración del modelo**, congelando capas convolucionales y ajustando la capa final para clasificación específica.\n",
    "5. **Entrenamiento y validación**, registrando pérdida y precisión por época.\n",
    "6. **Visualización de métricas** para evaluar el rendimiento.\n",
    "7. **Guardado del modelo** entrenado en disco.\n",
    "8. **Fase de inferencia** sobre una imagen del conjunto de validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b03412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 📦 Importación de librerías necesarias\n",
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from google.colab import drive\n",
    "from PIL import Image  # Para manipular imágenes\n",
    "\n",
    "print(\"✅ Librerías importadas correctamente\")\n",
    "\n",
    "try:\n",
    "    # 📥 Descarga del dataset desde KaggleHub\n",
    "    path = kagglehub.dataset_download(\"sriramr/fruits-fresh-and-rotten-for-classification\")\n",
    "    print(\"✅ Dataset descargado correctamente\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "\n",
    "    # ⚙️ Parámetros de configuración\n",
    "    batch_size = 128  # Tamaño de batch para entrenamiento\n",
    "    img_size = 224    # Tamaño de entrada esperado por ResNet18\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"🚀 Dispositivo de ejecución: {device}\")\n",
    "\n",
    "    # 🔄 Transformaciones para preprocesamiento de imágenes\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])  # Valores estándar de ImageNet\n",
    "    ])\n",
    "    print(\"✅ Transformaciones definidas\")\n",
    "\n",
    "    # 📁 Definición de rutas del dataset\n",
    "    train_data_dir = os.path.join(path, 'dataset', 'train')\n",
    "    val_data_dir = os.path.join(path, 'dataset', 'test')\n",
    "\n",
    "    # 🧾 Carga de datasets con transformaciones\n",
    "    train_dataset = datasets.ImageFolder(root=train_data_dir, transform=transform)\n",
    "    val_dataset = datasets.ImageFolder(root=val_data_dir, transform=transform)\n",
    "    class_names = train_dataset.classes\n",
    "\n",
    "    print(f\"🔍 Clases detectadas: {class_names}\")\n",
    "    print(f\"📊 Imágenes de entrenamiento: {len(train_dataset)}\")\n",
    "    print(f\"📊 Imágenes de validación: {len(val_dataset)}\")\n",
    "\n",
    "    # 🔁 Creación de DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # 🧠 Carga del modelo preentrenado\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    print(\"🎯 Modelo ResNet18 cargado (preentrenado en ImageNet)\")\n",
    "\n",
    "    # ❄️ Congelar parámetros para usar como extractor de características\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # 🔄 Reemplazo de la capa fully-connected para ajuste fino\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, len(class_names))  # Ajustamos la última capa al número de clases\n",
    "    model = model.to(device)\n",
    "    print(\"✅ Modelo ajustado y enviado al dispositivo\")\n",
    "\n",
    "    # 🔧 Configuración del entrenamiento\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "    epochs = 10\n",
    "\n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "    print(\"🚀 Comenzando entrenamiento...\")\n",
    "\n",
    "    # 🔁 Bucle de entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        # 🧪 Fase de validación\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        accuracy = 100 * correct / total\n",
    "        val_accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"📈 Epoch {epoch+1}/{epochs} | Train Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    print(\"✅ Entrenamiento completado\")\n",
    "\n",
    "    # 📊 Visualización de resultados\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Entrenamiento')\n",
    "    plt.plot(val_losses, label='Validación')\n",
    "    plt.title(\"Curva de Pérdida\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Pérdida\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracies, label='Precisión Validación', color='green')\n",
    "    plt.title(\"Precisión por Época\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Precisión (%)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 💾 Guardado del modelo\n",
    "    model_path = \"modelo.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"✅ Modelo guardado como {model_path}\")\n",
    "\n",
    "    # 🔍 Inferencia sobre imagen de validación\n",
    "    print(\"--- Fase de Inferencia ---\")\n",
    "    sample_image_path, _ = val_dataset.samples[0]\n",
    "    image = Image.open(sample_image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted_index = torch.max(outputs, 1)\n",
    "    predicted_class = class_names[predicted_index.item()]\n",
    "    print(f\"🔎 Resultado de inferencia: {predicted_class}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
