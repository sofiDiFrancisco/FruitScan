{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b0daed",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n de frutas frescas y podridas con ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578d46c",
   "metadata": {},
   "source": [
    "\n",
    "Este notebook implementa una soluci√≥n de clasificaci√≥n de frutas (frescas y podridas) usando una red neuronal convolucional preentrenada (ResNet18). Utiliza un dataset obtenido desde Kaggle Hub y realiza las siguientes etapas:\n",
    "\n",
    "1. Descarga y carga de datos.\n",
    "2. Transformaciones y preprocesamiento.\n",
    "3. Definici√≥n y ajuste del modelo.\n",
    "4. Entrenamiento y validaci√≥n.\n",
    "5. Visualizaci√≥n de m√©tricas.\n",
    "6. Guardado del modelo entrenado.\n",
    "7. Inferencia sobre una imagen de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as\n",
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from google.colab import drive\n",
    "from PIL import Image  # Para manejo de im√°genes\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "\n",
    "# Descarga del dataset desde Kaggle Hub\n",
    "try:\n",
    "    path = kagglehub.dataset_download(\"sriramr/fruits-fresh-and-rotten-for-classification\")\n",
    "    print(\"‚úÖ Dataset descargado correctamente\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "\n",
    "    # Configuraci√≥n general\n",
    "    batch_size = 128\n",
    "    img_size = 224\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"üöÄ Dispositivo de ejecuci√≥n: {device}\")\n",
    "\n",
    "    # Transformaciones para las im√°genes\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    print(\"‚úÖ Configuraci√≥n y transformaciones definidas\")\n",
    "\n",
    "    # Cargar datasets\n",
    "    train_data_dir = os.path.join(path, 'dataset', 'train')\n",
    "    val_data_dir = os.path.join(path, 'dataset', 'test')\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root=train_data_dir, transform=transform)\n",
    "    val_dataset = datasets.ImageFolder(root=val_data_dir, transform=transform)\n",
    "\n",
    "    class_names = train_dataset.classes\n",
    "    print(f\"üîç Clases detectadas: {class_names}\")\n",
    "    print(f\"üìä Total de im√°genes de entrenamiento: {len(train_dataset)}\")\n",
    "    print(f\"üìä Total de im√°genes de validaci√≥n: {len(val_dataset)}\")\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    print(\"‚úÖ Dataset cargado y dividido correctamente\")\n",
    "\n",
    "    # Cargar modelo ResNet18 preentrenado\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    print(\"üéØ ResNet18 cargado\")\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    print(\"‚ùÑÔ∏è Par√°metros congelados\")\n",
    "\n",
    "    # Reemplazo de la capa final\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, len(class_names))\n",
    "    print(f\"üîÑ Capa FC reemplazada para {len(class_names)} clases\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    print(f\"üìå Modelo movido a {device}\")\n",
    "\n",
    "    # Funci√≥n de p√©rdida y optimizador\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "    epochs = 10\n",
    "\n",
    "    print(\"‚öôÔ∏è Configuraci√≥n de entrenamiento definida\")\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    print(\"üöÄ Comenzando entrenamiento...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        # Validaci√≥n\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        accuracy = 100 * correct / total\n",
    "        val_accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"‚úÖ Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"Train Loss: {epoch_loss:.4f} - \"\n",
    "              f\"Val Loss: {val_loss:.4f} - \"\n",
    "              f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    print(\"üéâ Entrenamiento completado!\")\n",
    "\n",
    "    # Visualizaci√≥n de resultados\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Entrenamiento')\n",
    "    plt.plot(val_losses, label='Validaci√≥n')\n",
    "    plt.xlabel('√âpocas')\n",
    "    plt.ylabel('P√©rdida')\n",
    "    plt.title('Curva de P√©rdida')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracies, label='Validaci√≥n', color='green')\n",
    "    plt.xlabel('√âpocas')\n",
    "    plt.ylabel('Precisi√≥n (%)')\n",
    "    plt.title('Precisi√≥n en Validaci√≥n')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Guardar modelo\n",
    "    try:\n",
    "        model_path = \"modelo.pth\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"üíæ Modelo guardado como: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al guardar el modelo: {e}\")\n",
    "\n",
    "    # Inferencia\n",
    "    print(\"--- Fase de Inferencia ---\")\n",
    "    sample_image_path, _ = val_dataset.samples[0]\n",
    "    print(f\"‚è≥ Inferencia sobre: {sample_image_path}\")\n",
    "\n",
    "    image = Image.open(sample_image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted_class_index = torch.max(outputs, 1)\n",
    "\n",
    "    predicted_class_name = class_names[predicted_class_index.item()]\n",
    "    print(f\"‚úÖ La fruta detectada es: {predicted_class_name}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error inesperado: {e}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
