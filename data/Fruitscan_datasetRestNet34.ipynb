{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n de Frutas Frescas vs. Podridas con ResNet34 - An√°lisis Profundo\n",
    "\n",
    "Este notebook mejorado incluye un an√°lisis exhaustivo del modelo, visualizaciones avanzadas y t√©cnicas para mejorar la reproducibilidad y rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n inicial mejorada\n",
    "import random\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Fijar semillas para reproducibilidad\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n inicial completada con semilla fija\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis de Arquitectura ResNet34\n",
    "\n",
    "La arquitectura ResNet34 utiliza conexiones residuales que permiten entrenar redes muy profundas (34 capas en este caso). Para nuestro problema de clasificaci√≥n binaria:\n",
    "\n",
    "- **Capas congeladas**: Todas excepto la √∫ltima capa FC\n",
    "- **Transfer Learning**: Aprovecha patrones aprendidos en ImageNet\n",
    "- **Capa FC personalizada**: Adaptada a nuestras 2 clases (fresco/podrido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n mejorada del modelo\n",
    "def initialize_model(num_classes):\n",
    "    model = models.resnet34(pretrained=True)\n",
    "    \n",
    "    # Congelar par√°metros inicialmente\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Reemplazar capa FC\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    # Descongelar √∫ltimas capas para fine-tuning\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'layer4' in name or 'fc' in name:\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    return model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = initialize_model(2).to(device)\n",
    "\n",
    "# Mostrar par√°metros entrenables\n",
    "print(\"\\nüîç Par√°metros entrenables:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Mejorada\n",
    "\n",
    "A√±adimos transformaciones adicionales para mejorar la generalizaci√≥n del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones mejoradas\n",
    "img_size = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Transformaciones con data augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento con Early Stopping y LR Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n mejorada de entrenamiento\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15):\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    counter = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Fase de entrenamiento\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Fase de validaci√≥n\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        train_loss = running_loss/len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        accuracy = 100*correct/total\n",
    "        \n",
    "        # Actualizar scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Guardar m√©tricas\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(accuracy)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f} - \"\n",
    "              f\"Val Loss: {val_loss:.4f} - \"\n",
    "              f\"Accuracy: {accuracy:.2f}% - \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaciones Mejoradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(train_losses, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Gr√°fico de p√©rdidas\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_losses, label='Entrenamiento')\n",
    "    plt.plot(val_losses, label='Validaci√≥n')\n",
    "    plt.xlabel('√âpocas')\n",
    "    plt.ylabel('P√©rdida')\n",
    "    plt.title('Curva de P√©rdida')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Gr√°fico de precisi√≥n\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(val_accuracies, color='green')\n",
    "    plt.xlabel('√âpocas')\n",
    "    plt.ylabel('Precisi√≥n (%)')\n",
    "    plt.title('Precisi√≥n en Validaci√≥n')\n",
    "    \n",
    "    # Matriz de confusi√≥n\n",
    "    plt.subplot(1, 3, 3)\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, \n",
    "                yticklabels=class_names)\n",
    "    plt.xlabel('Predicho')\n",
    "    plt.ylabel('Verdadero')\n",
    "    plt.title('Matriz de Confusi√≥n')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flujo Principal Mejorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Descargar y cargar datos\n",
    "    path = kagglehub.dataset_download(\"sriramr/fruits-fresh-and-rotten-for-classification\")\n",
    "    train_data_dir = os.path.join(path, 'dataset', 'train')\n",
    "    val_data_dir = os.path.join(path, 'dataset', 'test')\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(root=train_data_dir, transform=train_transform)\n",
    "    val_dataset = datasets.ImageFolder(root=val_data_dir, transform=val_transform)\n",
    "    \n",
    "    class_names = train_dataset.classes\n",
    "    print(f\"üîç Clases detectadas: {class_names}\")\n",
    "    \n",
    "    # DataLoaders\n",
    "    batch_size = 64  # Reducido para permitir data augmentation\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Entrenamiento\n",
    "    train_losses, val_losses, val_accuracies = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20)\n",
    "    \n",
    "    # Visualizaci√≥n\n",
    "    plot_metrics(train_losses, val_losses, val_accuracies)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretaci√≥n de Resultados\n",
    "\n",
    "1. **Curvas de Entrenamiento**:\n",
    "   - P√©rdida de entrenamiento deber√≠a disminuir consistentemente\n",
    "   - P√©rdida de validaci√≥n deber√≠a seguir una tendencia similar\n",
    "   - Grandes brechas indican sobreajuste\n",
    "\n",
    "2. **Matriz de Confusi√≥n**:\n",
    "   - Diagonal principal muestra clasificaciones correctas\n",
    "   - Otras celdas muestran confusiones entre clases\n",
    "\n",
    "3. **Learning Rate**:\n",
    "   - Reducci√≥n autom√°tica cuando val_loss no mejora\n",
    "   - Mejora la fine-tuning en etapas finales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
