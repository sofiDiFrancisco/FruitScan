{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentación del Código para Clasificación de Frutas\n",
    "\n",
    "Este documento describe un codigo diseñado para entrenar un modelo de clasificación de imágenes de frutas utilizando PyTorch. El proceso abarca desde la preparación de los datos hasta el entrenamiento del modelo y la visualización de su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 1: Importación de Librerías\n",
    "\n",
    "Se importan las librerías esenciales para el entrenamiento del modelo de clasificación de frutas.\n",
    "\n",
    "* **PyTorch (`torch`, `torch.nn`, `torch.optim`) y `torchvision`**: Fundamentales para definir el modelo de red neuronal, cargar y transformar los datos de imagen, y gestionar el proceso de entrenamiento.\n",
    "* **`matplotlib.pyplot`**: Se usa para generar gráficos, específicamente la curva de pérdida, que permite visualizar el progreso del entrenamiento.\n",
    "* **`os`**: Proporciona funcionalidades para interactuar con el sistema operativo, como la gestión de rutas de archivos.\n",
    "* **`google.colab.drive`**: Permite montar Google Drive en el entorno de Colab para acceder a los datos almacenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Importar librerías necesarias\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 2: Configuración Inicial y Transformaciones\n",
    "\n",
    "En este paso, se establecen los parámetros cruciales y se definen las transformaciones necesarias para procesar las imágenes del *dataset*.\n",
    "\n",
    "* **`batch_size`**: Define el número de imágenes procesadas en cada iteración de entrenamiento.\n",
    "* **`img_size`**: Especifica las dimensiones a las que se redimensionarán todas las imágenes.\n",
    "* **`device`**: Determina si se utilizará una GPU (`cuda`) o la CPU para el entrenamiento, priorizando la GPU si está disponible.\n",
    "* **`data_dir`**: La ruta donde se encuentran las imágenes del *dataset* de frutas.\n",
    "\n",
    "Las **transformaciones** se aplican a las imágenes para asegurar uniformidad y normalización:\n",
    "\n",
    "* **`transforms.Resize((img_size, img_size))`**: Redimensiona todas las imágenes al tamaño definido (`224x224`).\n",
    "* **`transforms.ToTensor()`**: Convierte las imágenes a tensores de PyTorch.\n",
    "* **`transforms.Normalize(...)`**: Normaliza los valores de los píxeles utilizando la media y desviación estándar predefinidas de ImageNet, lo que ayuda al modelo a aprender de manera más eficiente.\n",
    "\n",
    "Luego, se carga el *dataset* completo de imágenes y se divide en conjuntos de entrenamiento (80%) y validación (20%) para evaluar el rendimiento del modelo en datos no vistos. La semilla (`torch.manual_seed(42)`) se fija para asegurar la reproducibilidad de la división. Finalmente, se crean `DataLoader` para cargar los datos en lotes durante el entrenamiento y la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: Configuración Inicial\n",
    "\n",
    "batch_size = 8\n",
    "img_size = 224\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_dir = \"/content/drive/MyDrive/FruitScan/data/fruits\"\n",
    "\n",
    "# Transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Cargar dataset\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# Dividir dataset\n",
    "val_split = 0.2\n",
    "val_size = int(len(full_dataset) * val_split)\n",
    "train_size = len(full_dataset) - val_size\n",
    "torch.manual_seed(42)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 3: Definición del Modelo\n",
    "\n",
    "Este paso se enfoca en la construcción y preparación del modelo de red neuronal para la tarea de clasificación.\n",
    "\n",
    "Se utiliza un modelo **VGG19 preentrenado** en ImageNet. El uso de un modelo preentrenado permite aprovechar las características visuales generales que ya ha aprendido de un *dataset* grande y diverso, lo que es una técnica conocida como *transfer learning*.\n",
    "\n",
    "Las **capas convolucionales** del VGG19 se **congelan** (`param.requires_grad = False`). Esto significa que sus pesos no se actualizarán durante el entrenamiento, manteniendo las características de alto nivel aprendidas.\n",
    "\n",
    "Finalmente, se modifica la **capa final (clasificador)** del modelo. La capa original de salida de VGG19 se reemplaza por una nueva capa lineal (`nn.Linear`) con el número de salidas igual a la cantidad de clases de frutas en nuestro *dataset*. Solo los parámetros de esta nueva capa se entrenarán, adaptando el modelo a nuestra tarea específica. El modelo se mueve al dispositivo (`cuda` o `cpu`) configurado previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Definición del Modelo\n",
    "\n",
    "model = models.vgg19(pretrained=True)\n",
    "\n",
    "# Congelar capas convolucionales (transfer learning)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modificar la capa final (classifier)\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, len(class_names))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 4: Configuración de Entrenamiento\n",
    "\n",
    "Aquí se definen los componentes clave para el proceso de entrenamiento del modelo.\n",
    "\n",
    "* **Función de pérdida (`criterion`)**: Se elige `nn.CrossEntropyLoss()`, que es la función de pérdida estándar y más adecuada para problemas de clasificación multiclase. Mide la diferencia entre las probabilidades predichas por el modelo y las etiquetas verdaderas.\n",
    "* **Optimizador (`optimizer`)**: Se utiliza `optim.Adam`. Este es un optimizador eficiente y adaptable que ajusta los pesos del modelo durante el entrenamiento. Es importante destacar que el optimizador solo actuará sobre los parámetros de la capa final (`model.classifier.parameters()`) ya que las capas convolucionales han sido congeladas. La tasa de aprendizaje (`lr=0.001`) controla el tamaño de los pasos que el optimizador da para ajustar los pesos.\n",
    "* **Épocas (`epochs`)**: Se define el número de veces que el modelo recorrerá todo el *dataset* de entrenamiento. En este caso, el modelo será entrenado por 10 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Configuración de Entrenamiento\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 5: Entrenamiento del Modelo\n",
    "\n",
    "Este es el núcleo del proceso, donde el modelo aprende de los datos.\n",
    "\n",
    "Se inicializan dos listas, `train_losses` y `val_losses`, para almacenar el valor de la pérdida en cada época, tanto para el conjunto de entrenamiento como para el de validación, respectivamente.\n",
    "\n",
    "El entrenamiento se itera a través del número definido de **épocas**. En cada época:\n",
    "\n",
    "1.  **Modo de entrenamiento (`model.train()`)**: El modelo se establece en modo de entrenamiento, lo que habilita funcionalidades como *dropout* y normalización por lotes.\n",
    "2.  **Bucle de entrenamiento**: Se itera sobre los lotes de imágenes y etiquetas del `train_loader`.\n",
    "    * Las imágenes y etiquetas se mueven al dispositivo (`device`).\n",
    "    * Los gradientes se ponen a cero (`optimizer.zero_grad()`) para evitar la acumulación de gradientes de iteraciones anteriores.\n",
    "    * Se realizan predicciones (`outputs = model(images)`).\n",
    "    * Se calcula la **pérdida de entrenamiento** (`loss = criterion(outputs, labels)`).\n",
    "    * Se calcula el gradiente de la pérdida con respecto a los pesos del modelo (`loss.backward()`).\n",
    "    * Los pesos del modelo se actualizan (`optimizer.step()`).\n",
    "    * La pérdida acumulada se registra.\n",
    "3.  La **pérdida promedio de la época de entrenamiento** se calcula y se almacena en `train_losses`.\n",
    "4.  **Validación**:\n",
    "    * El modelo se establece en modo de evaluación (`model.eval()`), deshabilitando *dropout* y normalización por lotes para una evaluación consistente.\n",
    "    * Se deshabilitan los cálculos de gradientes (`with torch.no_grad():`) para ahorrar memoria y computación durante la inferencia.\n",
    "    * Se itera sobre los lotes del `val_loader`, calculando la **pérdida de validación** y el número de predicciones correctas para determinar la **precisión**.\n",
    "    * La **pérdida promedio de la época de validación** se calcula y se almacena en `val_losses`.\n",
    "5.  Se imprime el progreso de la época, incluyendo la pérdida de entrenamiento y validación, y la precisión en el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5: Entrenamiento del Modelo\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"\\u2705 Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f} - Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 6: Visualización de la Curva de Pérdida\n",
    "\n",
    "La visualización de la curva de pérdida es una herramienta crucial para entender el comportamiento del modelo durante el entrenamiento.\n",
    "\n",
    "Se utiliza `matplotlib.pyplot` para graficar las pérdidas de entrenamiento y validación registradas a lo largo de las épocas.\n",
    "\n",
    "* El eje X representa las **épocas**.\n",
    "* El eje Y representa el valor de la **pérdida**.\n",
    "* Se trazan dos líneas: una para la **pérdida de entrenamiento** (`train_losses`) y otra para la **pérdida de validación** (`val_losses`).\n",
    "* La gráfica incluye etiquetas para los ejes, un título descriptivo y una leyenda para distinguir ambas curvas.\n",
    "\n",
    "Esta visualización ayuda a:\n",
    "* **Identificar si el modelo está aprendiendo**: Si ambas curvas disminuyen, el modelo está aprendiendo.\n",
    "* **Detectar sobreajuste (overfitting)**: Si la pérdida de entrenamiento sigue disminuyendo mientras la pérdida de validación comienza a aumentar, indica que el modelo está memorizando el *dataset* de entrenamiento y no generaliza bien a datos nuevos.\n",
    "* **Detectar subajuste (underfitting)**: Si ambas pérdidas permanecen altas, el modelo podría no ser lo suficientemente complejo o no ha entrenado lo suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 6: Visualización de la Curva de Pérdida\n",
    "\n",
    "plt.plot(train_losses, label='Entrenamiento')\n",
    "plt.plot(val_losses, label='Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.title('Curva de Pérdida')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 7: Guardado del Modelo\n",
    "\n",
    "Finalmente, se guarda el estado entrenado del modelo para su uso futuro, como la inferencia en nuevas imágenes.\n",
    "\n",
    "El `state_dict()` del modelo (que contiene todos los parámetros aprendidos) se guarda en un archivo con el nombre `fruitscan_model.pth`. Esto permite cargar el modelo en el futuro sin necesidad de reentrenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 7: Guardado del Modelo\n",
    "\n",
    "model_path = \"fruitscan_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"\\n✅ Modelo guardado como: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
